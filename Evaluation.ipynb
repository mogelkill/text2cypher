{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j.exceptions import ClientError, CypherSyntaxError\n",
    "from src.llm_query_generator.llm import OpenAILLM\n",
    "from src.llm_query_generator.pipelines import DataBaseDescriptor, AgentPipeline, QAPipeline\n",
    "from src.llm_query_generator.pipelines.qa_pipeline import clean_generation,format_result_for_qa\n",
    "from src.llm_query_generator.chat_history import ChatHistory\n",
    "from src.llm_query_generator.db import Neo4jAdapter\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Selection Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DESCRIPTORS = [\n",
    "    DataBaseDescriptor(\n",
    "        \"MovieDatabase\", \"A neo4j database containing information about movies, actors and directors\", None\n",
    "    ),\n",
    "        DataBaseDescriptor(\n",
    "        \"CLEVR\", \"A neo4j database containing information about underground train stations and underground train lines with their architecture and other addtitional informations\", None\n",
    "    ),\n",
    "    DataBaseDescriptor(\n",
    "        \"Northwind\", \"A neo4j database containing an traditional retail-system with products, orders, customers, suppliers and employees\", None\n",
    "    )\n",
    "]\n",
    "\n",
    "JSON_LLM = OpenAILLM(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=50,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "agent_pipeline = AgentPipeline(JSON_LLM,None,None,DATA_BASE_DESCRIPTORS)\n",
    "clevr_decision_df = pd.read_csv(\"data/Decision_Evaluation/Databasedecision_Northwind.csv\",sep=\";\")\n",
    "clevr_decision_df[\"Chatbot Decision\"] = \"\"\n",
    "clevr_decision_df[\"Duration\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = agent_pipeline.generate_decision_prompt(\"In which movies did Keanu Reeves play?\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decide if you can answer the question only with the information of the chat history and if not which Database should be used to answer the question.\n",
      "Important: You must answer in JSON format!\n",
      "You have the follwing Databases available:\n",
      "MovieDatabase: A neo4j database containing information about movies, actors and directors\n",
      "CLEVR: A neo4j database containing information about underground train stations and underground train lines with their architecture and other addtitional informations\n",
      "Northwind: A neo4j database containing an traditional retail-system with products, orders, customers, suppliers and employees\n",
      "\n",
      "The question is:In which movies did Keanu Reeves play?\n",
      "The current chat history is:\n",
      "[{'role': 'system', 'content': 'You are a helpfull chat assistant that helps the user answer questions.'}]\n",
      "Follow this example for the output:\n",
      "{\n",
      "  database: Literal[\"MovieDatabase\", \"CLEVR\", \"Northwind\", \"None\"],\n",
      "  can_answer_from_history: bool,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Decisions: 44it [01:08,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(clevr_decision_df.iterrows(),desc=\"Generating Decisions\"):\n",
    "    question = row[\"Question\"]\n",
    "    start = time()\n",
    "    decision = agent_pipeline.decide(question,history)\n",
    "    end = time()\n",
    "    duration = end - start\n",
    "    row[\"Chatbot Decision\"] = str(decision[\"database\"])\n",
    "    row[\"Duration\"] = duration\n",
    "    clevr_decision_df.to_csv(\"data/Decision_Evaluation/Databasedecision_Northwind_with_decision.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Decision_Evaluation/Databasedecision_Northwind_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_duration = df[\"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Duration: 1.5561840371652083\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Duration: {avg_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"Expected Database\"] == df[\"Chatbot Decision\"]).sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "northwind_with_decisions = pd.read_csv(\"data/Decision_Evaluation/Databasedecision_Northwind_with_decision.csv\",sep=\";\")\n",
    "movies_with_decisions = pd.read_csv(\"data/Decision_Evaluation/Databasedecision_MovieDatabase_with_decision.csv\",sep=\";\")\n",
    "clevr_with_decisions = pd.read_csv(\"data/Decision_Evaluation/Databasedecision_CLEVR_with_decisions.csv\",sep=\";\")\n",
    "all_decisions_df = pd.concat([northwind_with_decisions,movies_with_decisions,clevr_with_decisions],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decisions_df.to_csv(\"data/Decision_Evaluation/All_Database_Decisions.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_duration = all_decisions_df[\"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Duration: 1.9010669601724504\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Duration: {avg_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "print(len(all_decisions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    }
   ],
   "source": [
    "print((all_decisions_df[\"Expected Database\"] == all_decisions_df[\"Chatbot Decision\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645390070921985"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_decisions_df[\"Expected Database\"] == all_decisions_df[\"Chatbot Decision\"]).sum() / len(all_decisions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat from History Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 step reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DESCRIPTORS = [\n",
    "    DataBaseDescriptor(\n",
    "        \"MovieDatabase\", \"A neo4j database containing information about movies, actors and directors\", None\n",
    "    ),\n",
    "        DataBaseDescriptor(\n",
    "        \"CLEVR\", \"A neo4j database containing information about underground train stations and underground train lines with their architecture and other addtitional informations\", None\n",
    "    ),\n",
    "    DataBaseDescriptor(\n",
    "        \"Northwind\", \"A neo4j database containing an traditional retail-system with products, orders, customers, suppliers and employees\", None\n",
    "    )\n",
    "]\n",
    "\n",
    "JSON_LLM = OpenAILLM(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=50,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "agent_pipeline = AgentPipeline(JSON_LLM,None,None,DATA_BASE_DESCRIPTORS)\n",
    "clevr_decision_history_df = pd.read_csv(\"data/Decision_Evaluation/0_Step_History_Movie.csv\",sep=\";\")\n",
    "history_df_working = clevr_decision_history_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_working[\"Used History Chatbot Decision\"] = \"\"\n",
    "history_df_working[\"Duration\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Decisions: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Decisions: 114it [02:52,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(history_df_working.iterrows(),desc=\"Generating Decisions\"):\n",
    "    question = row[\"Question\"]\n",
    "    start = time()\n",
    "    decision = agent_pipeline.decide(question,history)\n",
    "    end = time()\n",
    "    duration = end - start\n",
    "    history_df_working.loc[index,\"Used History Chatbot Decision\"] = str(decision[\"can_answer_from_history\"])\n",
    "    history_df_working.loc[index,\"Duration\"] = duration\n",
    "    history_df_working.to_csv(\"data/Decision_Evaluation/0_Step_History_Movie_with_decision.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 step reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DESCRIPTORS = [\n",
    "    DataBaseDescriptor(\n",
    "        \"MovieDatabase\", \"A neo4j database containing information about movies, actors and directors\", None\n",
    "    ),\n",
    "        DataBaseDescriptor(\n",
    "        \"CLEVR\", \"A neo4j database containing information about underground train stations and underground train lines with their architecture and other addtitional informations\", None\n",
    "    ),\n",
    "    DataBaseDescriptor(\n",
    "        \"Northwind\", \"A neo4j database containing an traditional retail-system with products, orders, customers, suppliers and employees\", None\n",
    "    )\n",
    "]\n",
    "\n",
    "JSON_LLM = OpenAILLM(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=50,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "agent_pipeline = AgentPipeline(JSON_LLM,None,None,DATA_BASE_DESCRIPTORS)\n",
    "clevr_decision_history_df = pd.read_csv(\"data/Decision_Evaluation/1_Step_History_Movie.csv\",sep=\";\")\n",
    "history_df_working = clevr_decision_history_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_working[\"Used History Chatbot Decision\"] = \"\"\n",
    "history_df_working[\"Duration\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Decisions: 114it [02:39,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(history_df_working.iterrows(),desc=\"Generating Decisions\"):\n",
    "    history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "    history.add_user_message(row[\"Question\"])\n",
    "    history.add_assistant_message(row[\"Answer Question\"])\n",
    "    question = row[\"Followup Question\"]\n",
    "    start = time()\n",
    "    decision = agent_pipeline.decide(question,history)\n",
    "    end = time()\n",
    "    duration = end - start\n",
    "    history_df_working.loc[index,\"Used History Chatbot Decision\"] = str(decision[\"can_answer_from_history\"])\n",
    "    history_df_working.loc[index,\"Duration\"] = duration\n",
    "    history_df_working.to_csv(\"data/Decision_Evaluation/1_Step_History_Movie_with_decision.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Decision_Evaluation/1_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_duration = df[\"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Duration: 1.3932930502975196\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Duration: {avg_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (df[\"Used History Expected\"] == df[\"Used History Chatbot Decision\"]).sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8508771929824561\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 step reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DESCRIPTORS = [\n",
    "    DataBaseDescriptor(\n",
    "        \"MovieDatabase\", \"A neo4j database containing information about movies, actors and directors\", None\n",
    "    ),\n",
    "        DataBaseDescriptor(\n",
    "        \"CLEVR\", \"A neo4j database containing information about underground train stations and underground train lines with their architecture and other addtitional informations\", None\n",
    "    ),\n",
    "    DataBaseDescriptor(\n",
    "        \"Northwind\", \"A neo4j database containing an traditional retail-system with products, orders, customers, suppliers and employees\", None\n",
    "    )\n",
    "]\n",
    "\n",
    "JSON_LLM = OpenAILLM(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=50,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "agent_pipeline = AgentPipeline(JSON_LLM,None,None,DATA_BASE_DESCRIPTORS)\n",
    "clevr_decision_history_df = pd.read_csv(\"data/Decision_Evaluation/2_Step_History_Movie.csv\",sep=\";\")\n",
    "history_df_working = clevr_decision_history_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_working[\"Used History Chatbot Decision\"] = \"\"\n",
    "history_df_working[\"Duration\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Decisions: 114it [02:24,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(history_df_working.iterrows(),desc=\"Generating Decisions\"):\n",
    "    history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "    history.add_user_message(row[\"Question 1\"])\n",
    "    history.add_assistant_message(row[\"Answer Question 1\"])\n",
    "    history.add_user_message(row[\"Question 2\"])\n",
    "    history.add_assistant_message(row[\"Answer Question 2\"])\n",
    "    question = row[\"Question 3\"]\n",
    "    start = time()\n",
    "    decision = agent_pipeline.decide(question,history)\n",
    "    end = time()\n",
    "    duration = end - start\n",
    "    history_df_working.loc[index,\"Used History Chatbot Decision\"] = str(decision[\"can_answer_from_history\"])\n",
    "    history_df_working.loc[index,\"Duration\"] = duration\n",
    "    history_df_working.to_csv(\"data/Decision_Evaluation/2_Step_History_Movie_with_decision.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Decision_Evaluation/2_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_duration = df[\"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Duration: 1.2688024232262058\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Duration: {avg_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (df[\"Used History Expected\"] == df[\"Used History Chatbot Decision\"]).sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7543859649122807\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Step reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Decision_Evaluation/3_Step_History_Movie.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    question_1 = row['Question 1'].replace('?', '').replace('.', '')\n",
    "    question_2 = row['Question 2'].replace('?', '').replace('.', '')\n",
    "    question_3 = row['Question 3'].replace('?', '').replace('.', '')\n",
    "    question_4 = f\"{question_1} and {question_2} and {question_3}?\"\n",
    "    data.loc[index, 'Question 4'] = question_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/Decision_Evaluation/3_Step_History_Movie.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DESCRIPTORS = [\n",
    "    DataBaseDescriptor(\n",
    "        \"MovieDatabase\", \"A neo4j database containing information about movies, actors and directors\", None\n",
    "    ),\n",
    "        DataBaseDescriptor(\n",
    "        \"CLEVR\", \"A neo4j database containing information about underground train stations and underground train lines with their architecture and other addtitional informations\", None\n",
    "    ),\n",
    "    DataBaseDescriptor(\n",
    "        \"Northwind\", \"A neo4j database containing an traditional retail-system with products, orders, customers, suppliers and employees\", None\n",
    "    )\n",
    "]\n",
    "\n",
    "JSON_LLM = OpenAILLM(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=50,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "agent_pipeline = AgentPipeline(JSON_LLM,None,None,DATA_BASE_DESCRIPTORS)\n",
    "clevr_decision_history_df = pd.read_csv(\"data/Decision_Evaluation/3_Step_History_Movie.csv\",sep=\";\")\n",
    "history_df_working = clevr_decision_history_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_working[\"Used History Chatbot Decision\"] = \"\"\n",
    "history_df_working[\"Duration\"] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Decisions: 114it [02:38,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(history_df_working.iterrows(),desc=\"Generating Decisions\"):\n",
    "    history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "    history.add_user_message(row[\"Question 1\"])\n",
    "    history.add_assistant_message(row[\"Answer Question 1\"])\n",
    "    history.add_user_message(row[\"Question 2\"])\n",
    "    history.add_assistant_message(row[\"Answer Question 2\"])\n",
    "    history.add_user_message(row[\"Question 3\"])\n",
    "    history.add_assistant_message(row[\"Answer Question 3\"])\n",
    "    question = row[\"Question 4\"]\n",
    "    start = time()\n",
    "    decision = agent_pipeline.decide(question,history)\n",
    "    end = time()\n",
    "    duration = end - start\n",
    "    history_df_working.loc[index,\"Used History Chatbot Decision\"] = str(decision[\"can_answer_from_history\"])\n",
    "    history_df_working.loc[index,\"Duration\"] = duration\n",
    "    history_df_working.to_csv(\"data/Decision_Evaluation/3_Step_History_Movie_with_decision.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Decision_Evaluation/3_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_duration = df[\"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Duration: 1.38554430844491\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Duration: {avg_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (df[\"Used History Expected\"] == df[\"Used History Chatbot Decision\"]).sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8596491228070176\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CQL Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cql_evaluation_df = pd.read_json(\"questions.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lines = cql_evaluation_df.sample(n=500,replace=False,random_state=32)\n",
    "random_lines_working = random_lines.copy()\n",
    "random_lines_working.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEVR_DB_ADAPTER = Neo4jAdapter(\"bolt://localhost:7687\", \"\", \"\").connect()\n",
    "\n",
    "CHAT_LLM = OpenAILLM(api_key=os.environ.get(\"OPENAI_KEY\"), model=\"gpt-4-1106-preview\", temperature=0.2, max_tokens=200)\n",
    "QUERY_LLM = OpenAILLM(api_key=os.environ.get(\"OPENAI_KEY\"), model=\"gpt-4-1106-preview\", temperature=0.0, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lines_working[\"cleaned_query\"] = \"\"\n",
    "random_lines_working[\"duration_query_generation\"] = None\n",
    "random_lines_working[\"db_result\"] = \"\"\n",
    "random_lines_working[\"syntax_error\"] = False\n",
    "random_lines_working[\"timeout_error\"] = False\n",
    "random_lines_working[\"duration_query_execution\"] = None\n",
    "random_lines_working[\"chat_generation_answer\"] = \"\"\n",
    "random_lines_working[\"duration_chat_answer\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['question', 'cypher', 'group', 'answer', 'cleaned_query',\n",
      "       'duration_query_generation', 'db_result', 'syntax_error',\n",
      "       'duration_query_execution', 'chat_generation_answer',\n",
      "       'duration_chat_answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(random_lines_working.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries and Answers: 300it [20:15,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(random_lines_working.iterrows(),desc=\"Generating Queries and Answers\",total=len(random_lines_working)):\n",
    "    history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "    question = row[\"question\"]\n",
    "\n",
    "    query_prompt = CLEVR_DB_ADAPTER.build_prompt(question)\n",
    "    start_query_generation = time()\n",
    "    cleaned_query = clean_generation(QUERY_LLM.generate(query_prompt))\n",
    "    end_query_generation = time()\n",
    "    duration_query_generation = end_query_generation - start_query_generation\n",
    "    try:\n",
    "        start_query_execution = time()\n",
    "        db_result = CLEVR_DB_ADAPTER.execute(cleaned_query)\n",
    "        end_query_execution = time()\n",
    "        duration_query_execution = end_query_execution - start_query_execution\n",
    "\n",
    "        start_chat_generation = time()\n",
    "        chat_prompt = format_result_for_qa(question, db_result)\n",
    "        history.add_user_message(chat_prompt)\n",
    "        answer = CHAT_LLM.chat(history.format_for_model())\n",
    "        end_chat_generation = time()\n",
    "        duration_chat_answer = end_chat_generation-start_chat_generation\n",
    "        db_result_str = json.dumps(db_result)\n",
    "        syntax_error = False\n",
    "        timeout_error = False\n",
    "\n",
    "    except Exception as e:\n",
    "        if isinstance(e, CypherSyntaxError):\n",
    "            syntax_error = True\n",
    "        elif isinstance(e, ClientError):\n",
    "            timeout_error = True\n",
    "        db_result = None\n",
    "        db_result_str = None\n",
    "        duration_query_execution = None\n",
    "        duration_chat_answer = None\n",
    "        answer = None\n",
    "    \n",
    "\n",
    "    random_lines_working.loc[index,\"cleaned_query\"] = cleaned_query\n",
    "    random_lines_working.loc[index,\"duration_query_generation\"] = duration_query_generation\n",
    "    random_lines_working.loc[index,\"db_result\"] = db_result_str\n",
    "    random_lines_working.loc[index,\"syntax_error\"] = syntax_error\n",
    "    random_lines_working.loc[index,\"timeout_error\"] = timeout_error\n",
    "    random_lines_working.loc[index,\"duration_query_execution\"] = duration_query_execution\n",
    "    random_lines_working.loc[index,\"chat_generation_answer\"] = answer\n",
    "    random_lines_working.loc[index,\"duration_chat_answer\"] = duration_chat_answer\n",
    "\n",
    "    random_lines_working.to_csv(\"data/Generation_Evaluation/Clevr_Generation_0_shot_secondtry.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"data/Generation_Evaluation/Clevr_Generation_0_shot.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'I don't know the answer': 33\n"
     ]
    }
   ],
   "source": [
    "count = len(results_df[results_df[\"chat_generation_answer\"] == \"I don't know the answer.\"])\n",
    "print(f\"Count of 'I don't know the answer': {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_df = pd.read_csv(\"data/Generation_Evaluation/Clevr_Generation_0_shot_with_timeout_error.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_df = pd.DataFrame(columns=zero_shot_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['question', 'cypher', 'group', 'answer', 'cleaned_query',\n",
      "       'duration_query_generation', 'db_result', 'syntax_error',\n",
      "       'timeout_error', 'duration_query_execution', 'chat_generation_answer',\n",
      "       'duration_chat_answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES_CLEVR = \"\"\"\n",
    "Question: How many stations are between Snoiarty St and Groitz Lane?\n",
    "Cypher: MATCH path = shortestPath((start:STATION {name: 'Snoiarty St'})-[:EDGE*..50]-(end:STATION {name: 'Groitz Lane'}))\n",
    "RETURN LENGTH(path) - 1 AS stationsBetween\n",
    "\n",
    "Question: How many lines is the station Spriaords Palace on?\n",
    "Cypher: MATCH (:STATION {name: \"Spriaords Palace\"})-[r:EDGE]-()\n",
    "RETURN COUNT(DISTINCT r.line_id) AS NumberOfLines\n",
    "\n",
    "Question: How many music styles does Orange Screic pass through?\n",
    "Cypher: MATCH (s1:STATION)-[e:EDGE]->(s2:STATION) WHERE e.line_name = 'Orange Screic' UNWIND [s1.music, s2.music] AS musicStyle\n",
    "RETURN COUNT(DISTINCT musicStyle)\n",
    "\n",
    "Question: Can you get rail connections at Mclaewn Upon Thames?\n",
    "Cypher: MATCH (s1:STATION {name: \"Mclaewn Upon Thames\"})-[:EDGE]->(s2:STATION)\n",
    "RETURN s1.name AS Station, s2.name AS ConnectedStation, s1.has_rail AS HasRail\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEVR_DB_ADAPTER = Neo4jAdapter(\"bolt://localhost:7687\", \"\", \"\",FEW_SHOT_EXAMPLES_CLEVR).connect()\n",
    "\n",
    "CHAT_LLM = OpenAILLM(api_key=os.environ.get(\"OPENAI_KEY\"), model=\"gpt-4-1106-preview\", temperature=0.2, max_tokens=200)\n",
    "QUERY_LLM = OpenAILLM(api_key=os.environ.get(\"OPENAI_KEY\"), model=\"gpt-4-1106-preview\", temperature=0.0, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries and Answers: 100%|██████████| 500/500 [36:20<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(zero_shot_df.iterrows(),desc=\"Generating Queries and Answers\",total=len(zero_shot_df)):\n",
    "    history = ChatHistory().add_system_message(\"You are a helpfull chat assistant that helps the user answer questions.\")\n",
    "    question = row[\"question\"]\n",
    "\n",
    "    query_prompt = CLEVR_DB_ADAPTER.build_prompt(question)\n",
    "    start_query_generation = time()\n",
    "    cleaned_query = clean_generation(QUERY_LLM.generate(query_prompt))\n",
    "    end_query_generation = time()\n",
    "    duration_query_generation = end_query_generation - start_query_generation\n",
    "    try:\n",
    "        start_query_execution = time()\n",
    "        db_result = CLEVR_DB_ADAPTER.execute(cleaned_query)\n",
    "        end_query_execution = time()\n",
    "        duration_query_execution = end_query_execution - start_query_execution\n",
    "\n",
    "        start_chat_generation = time()\n",
    "        chat_prompt = format_result_for_qa(question, db_result)\n",
    "        history.add_user_message(chat_prompt)\n",
    "        answer = CHAT_LLM.chat(history.format_for_model())\n",
    "        end_chat_generation = time()\n",
    "        duration_chat_answer = end_chat_generation-start_chat_generation\n",
    "        db_result_str = json.dumps(db_result)\n",
    "        syntax_error = False\n",
    "        timeout_error = False\n",
    "\n",
    "    except Exception as e:\n",
    "        if isinstance(e, CypherSyntaxError):\n",
    "            syntax_error = True\n",
    "        elif isinstance(e, ClientError):\n",
    "            timeout_error = True\n",
    "        db_result = None\n",
    "        db_result_str = None\n",
    "        duration_query_execution = None\n",
    "        duration_chat_answer = None\n",
    "        answer = None\n",
    "    \n",
    "    few_shot_df.loc[index,\"question\"] = question\n",
    "    few_shot_df.loc[index,\"cypher\"] = row[\"cypher\"]\n",
    "    few_shot_df.loc[index,\"group\"] = row[\"group\"]\n",
    "    few_shot_df.loc[index,\"answer\"] = row[\"answer\"]\n",
    "    few_shot_df.loc[index,\"cleaned_query\"] = cleaned_query\n",
    "    few_shot_df.loc[index,\"duration_query_generation\"] = duration_query_generation\n",
    "    few_shot_df.loc[index,\"db_result\"] = db_result_str\n",
    "    few_shot_df.loc[index,\"syntax_error\"] = syntax_error\n",
    "    few_shot_df.loc[index,\"timeout_error\"] = timeout_error\n",
    "    few_shot_df.loc[index,\"duration_query_execution\"] = duration_query_execution\n",
    "    few_shot_df.loc[index,\"chat_generation_answer\"] = answer\n",
    "    few_shot_df.loc[index,\"duration_chat_answer\"] = duration_chat_answer\n",
    "\n",
    "    few_shot_df.to_csv(\"data/Generation_Evaluation/Clevr_Generation_few_shot_with_timeout_error.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"data/Generation_Evaluation/Clevr_Generation_few_shot_with_timeout_error.csv\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of syntax errors: 0\n",
      "Number of timeout errors: 0\n"
     ]
    }
   ],
   "source": [
    "syntax_errors = result[\"syntax_error\"].sum()\n",
    "timeout_errors = result[\"timeout_error\"].sum()\n",
    "\n",
    "print(f\"Number of syntax errors: {syntax_errors}\")\n",
    "print(f\"Number of timeout errors: {timeout_errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of empty db results: 27\n"
     ]
    }
   ],
   "source": [
    "empty_result_count = result['db_result'].value_counts()['[]']\n",
    "print(f\"Count of empty db results: {empty_result_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'I don't know the answer': 32\n"
     ]
    }
   ],
   "source": [
    "count = len(result[result[\"chat_generation_answer\"] == \"I don't know the answer.\"])\n",
    "print(f\"Count of 'I don't know the answer': {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_step_history_celvr_df = pd.read_csv(\"data/Decision_Evaluation/0_Step_History_Clevr_with_decision.csv\",sep=\";\")\n",
    "zero_step_history_movie_df = pd.read_csv(\"data/Decision_Evaluation/0_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zero_step_history_movie_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mzero_step_history_movie_df\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(zero_step_history_celvr_df))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zero_step_history_movie_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(zero_step_history_movie_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zero_step_history_df = pd.concat([zero_step_history_celvr_df,zero_step_history_movie_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "print(len(all_zero_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print((all_zero_step_history_df[\"Used History Expected\"] == all_zero_step_history_df[\"Used History Chatbot Decision\"]).sum() / len(all_zero_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5628224232486476\n"
     ]
    }
   ],
   "source": [
    "print(all_zero_step_history_df[\"Duration\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_history_celvr_df = pd.read_csv(\"data/Decision_Evaluation/1_Step_History_Clevr_with_decision.csv\",sep=\";\")\n",
    "one_step_history_movie_df = pd.read_csv(\"data/Decision_Evaluation/1_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(one_step_history_celvr_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_one_step_history_df = pd.read_csv(\"data/Decision_Evaluation/All_One_Step_History_Decisions.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "print(len(all_one_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822429906542056\n"
     ]
    }
   ],
   "source": [
    "print((all_one_step_history_df[\"Used History Expected\"] == all_one_step_history_df[\"Used History Chatbot Decision\"]).sum() / len(all_one_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5194765619028394\n"
     ]
    }
   ],
   "source": [
    "print(all_one_step_history_df[\"Duration\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_step_history_celvr_df = pd.read_csv(\"data/Decision_Evaluation/2_Step_History_Clevr_with_decision.csv\",sep=\";\")\n",
    "two_step_history_movie_df = pd.read_csv(\"data/Decision_Evaluation/2_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "print(len(two_step_history_movie_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_two_step_history_df = pd.read_csv(\"data/Decision_Evaluation/All_Two_Step_History_with_Decisions.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "print(len(all_two_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794392523364486\n"
     ]
    }
   ],
   "source": [
    "print((all_two_step_history_df[\"Used History Expected\"] == all_two_step_history_df[\"Used History Chatbot Decision\"]).sum() / len(all_two_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5202398756954159\n"
     ]
    }
   ],
   "source": [
    "print(all_two_step_history_df[\"Duration\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_step_history_celvr_df = pd.read_csv(\"data/Decision_Evaluation/3_Step_History_Clevr_with_decision.csv\",sep=\";\")\n",
    "three_step_history_movie_df = pd.read_csv(\"data/Decision_Evaluation/3_Step_History_Movie_with_decision.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "print(len(three_step_history_movie_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_three_step_history_df = pd.read_csv(\"data/Decision_Evaluation/All_Three_Step_History_with_Decisions.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "print(len(all_three_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8738317757009346\n"
     ]
    }
   ],
   "source": [
    "print((all_three_step_history_df[\"Used History Expected\"] == all_three_step_history_df[\"Used History Chatbot Decision\"]).sum() / len(all_three_step_history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6882413982230926\n"
     ]
    }
   ],
   "source": [
    "print(all_three_step_history_df[\"Duration\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_db_decisions_df = pd.read_csv(\"data/Decision_Evaluation/All_Database_Decisions.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "print(len(all_db_decisions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9645390070921985\n"
     ]
    }
   ],
   "source": [
    "print((all_db_decisions_df[\"Expected Database\"] == all_db_decisions_df[\"Chatbot Decision\"]).sum() / len(all_db_decisions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9010669601724504\n"
     ]
    }
   ],
   "source": [
    "print(all_db_decisions_df[\"Duration\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_df = pd.read_csv(\"data/Generation_Evaluation/Clevr_Generation_0_shot_with_timeout_error_with_evaluation.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of syntax errors: 48\n",
      "Number of timeout errors: 20\n"
     ]
    }
   ],
   "source": [
    "syntax_errors = zero_shot_df[\"syntax_error\"].sum()\n",
    "timeout_errors = zero_shot_df[\"timeout_error\"].sum()\n",
    "print(f\"Number of syntax errors: {syntax_errors}\")\n",
    "print(f\"Number of timeout errors: {timeout_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average duration query generation: 3.290248386859894\n",
      "Average duration query execution: 0.015288315350384234\n",
      "Average duration chat answer: 1.7156024537894123\n"
     ]
    }
   ],
   "source": [
    "duration_query_generation = zero_shot_df[\"duration_query_generation\"].mean()\n",
    "duration_query_execution = zero_shot_df[\"duration_query_execution\"].mean()\n",
    "duration_chat_answer = zero_shot_df[\"duration_chat_answer\"].mean()\n",
    "\n",
    "print(f\"Average duration query generation: {duration_query_generation}\")\n",
    "print(f\"Average duration query execution: {duration_query_execution}\")\n",
    "print(f\"Average duration chat answer: {duration_chat_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_accuracy = (zero_shot_df[\"Human Evaluation\"] == \"Correct\").sum() / len(zero_shot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution Accuracy: {execution_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_df = pd.read_csv(\"data/Generation_Evaluation/Clevr_Generation_few_shot_with_timeout_error_with_evaluation.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of syntax errors: 0\n",
      "Number of timeout errors: 0\n"
     ]
    }
   ],
   "source": [
    "syntax_errors = few_shot_df[\"syntax_error\"].sum()\n",
    "timeout_errors = few_shot_df[\"timeout_error\"].sum()\n",
    "print(f\"Number of syntax errors: {syntax_errors}\")\n",
    "print(f\"Number of timeout errors: {timeout_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average duration query generation: 3.008542133808136\n",
      "Average duration query execution: 0.009419580459594677\n",
      "Average duration chat answer: 1.3377295742034911\n"
     ]
    }
   ],
   "source": [
    "duration_query_generation = few_shot_df[\"duration_query_generation\"].mean()\n",
    "duration_query_execution = few_shot_df[\"duration_query_execution\"].mean()\n",
    "duration_chat_answer = few_shot_df[\"duration_chat_answer\"].mean()\n",
    "\n",
    "print(f\"Average duration query generation: {duration_query_generation}\")\n",
    "print(f\"Average duration query execution: {duration_query_execution}\")\n",
    "print(f\"Average duration chat answer: {duration_chat_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_accuracy = (few_shot_df[\"Human Evaluation\"] == \"Correct\").sum() / len(few_shot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution Accuracy: {execution_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "df = pd.read_csv(\"data/Decision_Evaluation/All_Database_Decisions.csv\", sep=\";\")\n",
    "\n",
    "filtered_df_movie = df[df[\"Expected Database\"] == \"MovieDatabase\"]\n",
    "filtered_df_clevr = df[df[\"Expected Database\"] == \"CLEVR\"]\n",
    "filtered_df_northwind = df[df[\"Expected Database\"] == \"None\"]\n",
    "filtered_df_none = df[df[\"Expected Database\"] == \"Northwind\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for MovieDatabase: 1.0\n",
      "Accuracy for CLEVR: 0.9\n",
      "Accuracy for Northwind: 1.0\n",
      "Accuracy for None: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_movie = (filtered_df_movie[\"Expected Database\"] == filtered_df_movie[\"Chatbot Decision\"]).mean()\n",
    "accuracy_clevr = (filtered_df_clevr[\"Expected Database\"] == filtered_df_clevr[\"Chatbot Decision\"]).mean()\n",
    "accuracy_northwind = (filtered_df_northwind[\"Expected Database\"] == filtered_df_northwind[\"Chatbot Decision\"]).mean()\n",
    "accuracy_none = (filtered_df_none[\"Expected Database\"] == filtered_df_none[\"Chatbot Decision\"]).mean()\n",
    "\n",
    "print(f\"Accuracy for MovieDatabase: {accuracy_movie}\")\n",
    "print(f\"Accuracy for CLEVR: {accuracy_clevr}\")\n",
    "print(f\"Accuracy for Northwind: {accuracy_northwind}\")\n",
    "print(f\"Accuracy for None: {accuracy_none}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for decision in MovieDatabase: 1.7899449598991264\n",
      "Mean time for decision in CLEVR: 2.206049556732178\n",
      "Mean time for decision in Northwind: 1.7431732575098673\n",
      "Mean time for decision in None: 1.529036003000596\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the mean time for decision per database\n",
    "mean_time_movie = filtered_df_movie[\"Duration\"].mean()\n",
    "mean_time_clevr = filtered_df_clevr[\"Duration\"].mean()\n",
    "mean_time_northwind = filtered_df_northwind[\"Duration\"].mean()\n",
    "mean_time_none = filtered_df_none[\"Duration\"].mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean time for decision in MovieDatabase: {mean_time_movie}\")\n",
    "print(f\"Mean time for decision in CLEVR: {mean_time_clevr}\")\n",
    "print(f\"Mean time for decision in Northwind: {mean_time_northwind}\")\n",
    "print(f\"Mean time for decision in None: {mean_time_none}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate the weigted accuracy for all databases\n",
    "weighted_accuracy = (accuracy_movie * len(filtered_df_movie) + accuracy_clevr * len(filtered_df_clevr) + accuracy_northwind * len(filtered_df_northwind)+ accuracy_none * len(filtered_df_none))/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Accuracy: 0.9645390070921985\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weighted Accuracy: {weighted_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "100\n",
      "30\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df_movie))\n",
    "print(len(filtered_df_clevr))\n",
    "print(len(filtered_df_northwind))\n",
    "print(len(filtered_df_none))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
